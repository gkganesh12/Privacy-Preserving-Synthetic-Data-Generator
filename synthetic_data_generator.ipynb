{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Synthetic Data Generator\n",
    "\n",
    "This notebook demonstrates how to use the Privacy-Preserving Synthetic Data Generator to create synthetic tabular data with privacy guarantees using CTGAN and Differential Privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom modules\n",
    "from data_preprocess import DataPreprocessor\n",
    "from model_train import PrivacyPreservingCTGAN\n",
    "from evaluate import SyntheticDataEvaluator\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n",
    "\n",
    "Load a CSV dataset and preprocess it for synthetic data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "# Replace with your dataset path\n",
    "data_path = 'your_dataset.csv'  # Update this path\n",
    "\n",
    "# For demonstration, you can use a sample dataset like this:\n",
    "# from sklearn.datasets import fetch_california_housing\n",
    "# housing = fetch_california_housing()\n",
    "# df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "# df['target'] = housing.target\n",
    "\n",
    "# Load your CSV file\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f'Dataset loaded successfully! Shape: {df.shape}')\n",
    "except Exception as e:\n",
    "    print(f'Error loading dataset: {e}')\n",
    "    # Create a sample dataset for demonstration\n",
    "    print('Creating a sample dataset for demonstration...')\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    housing = fetch_california_housing()\n",
    "    df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "    df['target'] = housing.target\n",
    "    print(f'Sample dataset created. Shape: {df.shape}')\n",
    "\n",
    "# Display data preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize preprocessor and detect column types\n",
    "preprocessor = DataPreprocessor()\n",
    "column_types = preprocessor.detect_column_types(df)\n",
    "\n",
    "# Display detected column types\n",
    "pd.DataFrame({\n",
    "    'Column': list(column_types.keys()),\n",
    "    'Type': list(column_types.values())\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "processed_df = preprocessor.fit_transform(df, column_types)\n",
    "\n",
    "# Display processed data preview\n",
    "print(f'Processed data shape: {processed_df.shape}')\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Synthetic Data Model\n",
    "\n",
    "Train a CTGAN model with optional Differential Privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure model parameters\n",
    "use_dp = True  # Set to False to disable Differential Privacy\n",
    "epsilon = 3.0  # Privacy budget (lower = more private)\n",
    "delta = 1e-5  # Privacy failure probability\n",
    "epochs = 300  # Training epochs\n",
    "batch_size = 500  # Batch size\n",
    "\n",
    "# Get discrete columns for CTGAN\n",
    "discrete_columns = [col for col in processed_df.columns \n",
    "                   if any(col.startswith(f\"{c}_\") for c in preprocessor.categorical_columns)]\n",
    "\n",
    "# Initialize model\n",
    "model = PrivacyPreservingCTGAN(\n",
    "    use_dp=use_dp,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(f'Training model with {\"Differential Privacy\" if use_dp else \"no privacy guarantees\"}...')\n",
    "training_metrics = model.train(processed_df, discrete_columns)\n",
    "\n",
    "# Display training metrics\n",
    "print(f'Training completed in {training_metrics[\"training_time\"]:.2f} seconds')\n",
    "print(f'Epochs: {training_metrics[\"epochs\"]}')\n",
    "\n",
    "if use_dp:\n",
    "    print(f'Final privacy guarantee: (ε={training_metrics[\"epsilon\"]:.2f}, δ={training_metrics[\"delta\"]:.1e})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Data\n",
    "\n",
    "Generate synthetic data using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Number of synthetic rows to generate\n",
    "num_rows = min(5000, len(df))\n",
    "\n",
    "# Generate synthetic data\n",
    "print(f'Generating {num_rows} synthetic rows...')\n",
    "synthetic_processed = model.generate(num_rows)\n",
    "\n",
    "# Inverse transform to original format\n",
    "synthetic_data = preprocessor.inverse_transform(synthetic_processed)\n",
    "\n",
    "print(f'Generated {len(synthetic_data)} synthetic rows successfully!')\n",
    "\n",
    "# Display synthetic data preview\n",
    "synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save synthetic data\n",
    "os.makedirs('output', exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = f\"output/{timestamp}_synthetic_data.csv\"\n",
    "\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f'Synthetic data saved to: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Synthetic Data\n",
    "\n",
    "Evaluate the quality and privacy of the generated synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize evaluator\n",
    "evaluator = SyntheticDataEvaluator()\n",
    "\n",
    "# Set column types\n",
    "evaluator.set_column_types(column_types)\n",
    "\n",
    "# Get privacy metrics if available\n",
    "privacy_metrics = None\n",
    "if use_dp:\n",
    "    privacy_metrics = {\n",
    "        'epsilon': training_metrics['epsilon'],\n",
    "        'delta': training_metrics['delta']\n",
    "    }\n",
    "\n",
    "# Select a target column for utility evaluation (if applicable)\n",
    "target_column = 'target' if 'target' in df.columns else None\n",
    "\n",
    "# Run evaluation\n",
    "print('Running evaluation...')\n",
    "results = evaluator.evaluate_all(\n",
    "    real_data=df,\n",
    "    synthetic_data=synthetic_data,\n",
    "    privacy_metrics=privacy_metrics,\n",
    "    target_column=target_column\n",
    ")\n",
    "\n",
    "print('Evaluation completed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display fidelity metrics\n",
    "print('\\nFidelity Metrics:')\n",
    "fidelity = results['fidelity']\n",
    "\n",
    "if 'overall_fidelity' in fidelity and fidelity['overall_fidelity'] is not None:\n",
    "    print(f\"Overall Fidelity: {fidelity['overall_fidelity']:.4f}\")\n",
    "\n",
    "if 'ks_mean' in fidelity and fidelity['ks_mean'] is not None:\n",
    "    print(f\"KS Similarity (Mean): {fidelity['ks_mean']:.4f}\")\n",
    "\n",
    "if 'correlation_similarity' in fidelity and fidelity['correlation_similarity'] is not None:\n",
    "    print(f\"Correlation Similarity: {fidelity['correlation_similarity']:.4f}\")\n",
    "\n",
    "if 'chi2_mean' in fidelity and fidelity['chi2_mean'] is not None:\n",
    "    print(f\"Chi-Square Similarity (Mean): {fidelity['chi2_mean']:.4f}\")\n",
    "\n",
    "if 'pmse_similarity' in fidelity and fidelity['pmse_similarity'] is not None:\n",
    "    print(f\"Propensity Similarity: {fidelity['pmse_similarity']:.4f}\")\n",
    "\n",
    "if 'real_vs_synthetic_auc' in fidelity and fidelity['real_vs_synthetic_auc'] is not None:\n",
    "    print(f\"Real vs Synthetic AUC: {fidelity['real_vs_synthetic_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display privacy metrics\n",
    "print('\\nPrivacy Metrics:')\n",
    "privacy = results['privacy']\n",
    "\n",
    "if 'privacy_score' in privacy and privacy['privacy_score'] is not None:\n",
    "    print(f\"Privacy Score: {privacy['privacy_score']:.4f}\")\n",
    "\n",
    "if 'membership_inference_auc' in privacy and privacy['membership_inference_auc'] is not None:\n",
    "    print(f\"Membership Inference AUC: {privacy['membership_inference_auc']:.4f}\")\n",
    "\n",
    "if 'epsilon' in privacy and privacy['epsilon'] is not None:\n",
    "    print(f\"Differential Privacy ε: {privacy['epsilon']:.2f}\")\n",
    "    if 'delta' in privacy and privacy['delta'] is not None:\n",
    "        print(f\"Differential Privacy δ: {privacy['delta']:.1e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display utility metrics if available\n",
    "if 'utility' in results:\n",
    "    print('\\nUtility Metrics:')\n",
    "    utility = results['utility']\n",
    "    \n",
    "    if 'utility_ratio' in utility and utility['utility_ratio'] is not None:\n",
    "        print(f\"Utility Ratio: {utility['utility_ratio']:.4f}\")\n",
    "    \n",
    "    if 'real_model_accuracy' in utility and utility['real_model_accuracy'] is not None:\n",
    "        print(f\"Real Model Accuracy: {utility['real_model_accuracy']:.4f}\")\n",
    "    \n",
    "    if 'synthetic_model_accuracy' in utility and utility['synthetic_model_accuracy'] is not None:\n",
    "        print(f\"Synthetic Model Accuracy: {utility['synthetic_model_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Comparisons\n",
    "\n",
    "Visualize comparisons between real and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot distributions for selected columns\n",
    "# Get numerical columns\n",
    "numerical_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# Select a subset of columns for visualization\n",
    "selected_columns = numerical_cols[:min(5, len(numerical_cols))]\n",
    "\n",
    "# Create distribution plots\n",
    "fig = evaluator.plot_distributions(\n",
    "    real_data=df,\n",
    "    synthetic_data=synthetic_data,\n",
    "    columns=selected_columns,\n",
    "    figsize=(15, 10)\n",
    ")\n",
    "\n",
    "plt.suptitle('Distribution Comparison: Real vs Synthetic', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot correlation heatmaps\n",
    "fig = evaluator.plot_correlation_comparison(\n",
    "    real_data=df,\n",
    "    synthetic_data=synthetic_data,\n",
    "    figsize=(15, 7)\n",
    ")\n",
    "\n",
    "plt.suptitle('Correlation Comparison: Real vs Synthetic', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Evaluation Results\n",
    "\n",
    "Save the evaluation results to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save evaluation results\n",
    "os.makedirs('output', exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_path = f\"output/{timestamp}_evaluation_results.json\"\n",
    "\n",
    "# Convert numpy values to Python native types for JSON serialization\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, \n",
    "                       np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "serializable_results = convert_to_serializable(results)\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "print(f'Evaluation results saved to: {results_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the Privacy-Preserving Synthetic Data Generator to create synthetic tabular data with privacy guarantees. The system allows for:\n",
    "\n",
    "1. Loading and preprocessing tabular data\n",
    "2. Training a CTGAN model with optional Differential Privacy\n",
    "3. Generating synthetic data with privacy guarantees\n",
    "4. Evaluating the fidelity, privacy, and utility of the synthetic data\n",
    "5. Visualizing comparisons between real and synthetic data\n",
    "\n",
    "The privacy-utility trade-off can be controlled by adjusting the privacy budget (ε) and other parameters.\n",
    "\n",
    "For a more interactive experience, you can use the Streamlit application by running:\n",
    "```\n",
    "streamlit run app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 }
}